{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch: 0 loss 0.00060468266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LSTMpred. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss 0.0006566109\n",
      "Epoch: 2 loss 0.00072662387\n",
      "Epoch: 3 loss 0.0008178054\n",
      "Epoch: 4 loss 0.0009309157\n",
      "Epoch: 5 loss 0.0010640989\n",
      "Epoch: 6 loss 0.0012131172\n",
      "Epoch: 7 loss 0.0013720018\n",
      "Epoch: 8 loss 0.0015339807\n",
      "Epoch: 9 loss 0.0016923982\n",
      "Epoch: 10 loss 0.0018414774\n",
      "Epoch: 11 loss 0.0019767506\n",
      "Epoch: 12 loss 0.0020952285\n",
      "Epoch: 13 loss 0.002195324\n",
      "Epoch: 14 loss 0.0022766304\n",
      "Epoch: 15 loss 0.002339658\n",
      "Epoch: 16 loss 0.00238553\n",
      "Epoch: 17 loss 0.0024157688\n",
      "Epoch: 18 loss 0.0024320674\n",
      "Epoch: 19 loss 0.0024361794\n",
      "Epoch: 20 loss 0.0024297808\n",
      "Epoch: 21 loss 0.0024144494\n",
      "Epoch: 22 loss 0.0023916152\n",
      "Epoch: 23 loss 0.002362545\n",
      "Epoch: 24 loss 0.0023283423\n",
      "Epoch: 25 loss 0.0022899727\n",
      "Epoch: 26 loss 0.0022482588\n",
      "Epoch: 27 loss 0.0022038985\n",
      "Epoch: 28 loss 0.0021574805\n",
      "Epoch: 29 loss 0.0021095073\n",
      "Epoch: 30 loss 0.0020603947\n",
      "Epoch: 31 loss 0.0020104966\n",
      "Epoch: 32 loss 0.0019601067\n",
      "Epoch: 33 loss 0.001909464\n",
      "Epoch: 34 loss 0.0018587789\n",
      "Epoch: 35 loss 0.0018082222\n",
      "Epoch: 36 loss 0.0017579366\n",
      "Epoch: 37 loss 0.0017080378\n",
      "Epoch: 38 loss 0.0016586243\n",
      "Epoch: 39 loss 0.0016097797\n",
      "Epoch: 40 loss 0.0015615706\n",
      "Epoch: 41 loss 0.0015140603\n",
      "Epoch: 42 loss 0.001467291\n",
      "Epoch: 43 loss 0.0014213019\n",
      "Epoch: 44 loss 0.0013761263\n",
      "Epoch: 45 loss 0.0013317917\n",
      "Epoch: 46 loss 0.0012883188\n",
      "Epoch: 47 loss 0.0012457268\n",
      "Epoch: 48 loss 0.0012040276\n",
      "Epoch: 49 loss 0.0011632326\n",
      "Epoch: 50 loss 0.0011233498\n",
      "Epoch: 51 loss 0.0010843881\n",
      "Epoch: 52 loss 0.0010463473\n",
      "Epoch: 53 loss 0.0010092326\n",
      "Epoch: 54 loss 0.00097304594\n",
      "Epoch: 55 loss 0.00093778624\n",
      "Epoch: 56 loss 0.00090344856\n",
      "Epoch: 57 loss 0.0008700341\n",
      "Epoch: 58 loss 0.0008375328\n",
      "Epoch: 59 loss 0.0008059433\n",
      "Epoch: 60 loss 0.00077525666\n",
      "Epoch: 61 loss 0.00074546866\n",
      "Epoch: 62 loss 0.00071656774\n",
      "Epoch: 63 loss 0.0006885447\n",
      "Epoch: 64 loss 0.00066139095\n",
      "Epoch: 65 loss 0.0006350951\n",
      "Epoch: 66 loss 0.000609647\n",
      "Epoch: 67 loss 0.0005850324\n",
      "Epoch: 68 loss 0.0005612382\n",
      "Epoch: 69 loss 0.00053825136\n",
      "Epoch: 70 loss 0.0005160616\n",
      "Epoch: 71 loss 0.00049464905\n",
      "Epoch: 72 loss 0.00047400003\n",
      "Epoch: 73 loss 0.00045409947\n",
      "Epoch: 74 loss 0.000434932\n",
      "Epoch: 75 loss 0.00041648225\n",
      "Epoch: 76 loss 0.00039872987\n",
      "Epoch: 77 loss 0.00038166132\n",
      "Epoch: 78 loss 0.00036525662\n",
      "Epoch: 79 loss 0.00034950054\n",
      "Epoch: 80 loss 0.00033437376\n",
      "Epoch: 81 loss 0.00031986108\n",
      "Epoch: 82 loss 0.00030594366\n",
      "Epoch: 83 loss 0.0002926031\n",
      "Epoch: 84 loss 0.0002798214\n",
      "Epoch: 85 loss 0.0002675809\n",
      "Epoch: 86 loss 0.00025586822\n",
      "Epoch: 87 loss 0.0002446616\n",
      "Epoch: 88 loss 0.00023394442\n",
      "Epoch: 89 loss 0.00022370135\n",
      "Epoch: 90 loss 0.00021391315\n",
      "Epoch: 91 loss 0.00020456445\n",
      "Epoch: 92 loss 0.0001956403\n",
      "Epoch: 93 loss 0.00018712359\n",
      "Epoch: 94 loss 0.00017899906\n",
      "Epoch: 95 loss 0.00017125078\n",
      "Epoch: 96 loss 0.00016386405\n",
      "Epoch: 97 loss 0.00015682395\n",
      "Epoch: 98 loss 0.00015011609\n",
      "Epoch: 99 loss 0.00014372688\n",
      "Epoch: 100 loss 0.00013764376\n",
      "Epoch: 101 loss 0.00013185332\n",
      "Epoch: 102 loss 0.00012634204\n",
      "Epoch: 103 loss 0.00012109747\n",
      "Epoch: 104 loss 0.000116109455\n",
      "Epoch: 105 loss 0.00011136405\n",
      "Epoch: 106 loss 0.00010685161\n",
      "Epoch: 107 loss 0.000102562306\n",
      "Epoch: 108 loss 9.848387e-05\n",
      "Epoch: 109 loss 9.460765e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import *\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "INPUT_SIZE=1\n",
    "HIDDEN_SIZE=16\n",
    "TIME_STEP=10\n",
    "\n",
    "EPOCH=200\n",
    "TRAIN_RATE=0.8\n",
    "# OPIMIZER='Adam'\n",
    "OPIMIZER='SGD'\n",
    "def SeriesGen(N):\n",
    "    x = torch.arange(1, N, 0.01)\n",
    "    return torch.sin(x)#+torch.cos(x)+torch.pow(x,2)\n",
    "\n",
    "\n",
    "def trainDataGen(seq, k):\n",
    "    dat = list()\n",
    "    L = len(seq)\n",
    "    for i in range(L - k - 1):\n",
    "        indat = seq[i:i + k]\n",
    "        outdat = seq[i + 1:i + k + 1]\n",
    "        dat.append((indat, outdat))\n",
    "    return dat\n",
    "\n",
    "'''数据归一化到0-1'''\n",
    "def normalization(y):\n",
    "    max_value = np.max(y)\n",
    "    min_value = np.min(y)\n",
    "    scalar = max_value - min_value\n",
    "    y = list(map(lambda x: x / scalar, y))\n",
    "    return  y\n",
    "\n",
    "'''产生数据'''\n",
    "DATA_SIZE=10\n",
    "y = SeriesGen(DATA_SIZE).numpy()\n",
    "y=normalization(y)\n",
    "dat = trainDataGen(y, TIME_STEP)\n",
    "\n",
    "'''训练数据和测试数据设置'''\n",
    "train_size = int(len(dat) * TRAIN_RATE)\n",
    "test_size = len(dat) - train_size\n",
    "train_y = dat[:train_size]\n",
    "test_y = dat[train_size:]\n",
    "\n",
    "\n",
    "# test_x = range(int(len(dat) * TRAIN_RATE), len(dat))\n",
    "\n",
    "\n",
    "\n",
    "class LSTMpred(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(LSTMpred, self).__init__()\n",
    "        self.input_dim = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
    "    #     self.hidden = self.init_hidden()\n",
    "    #\n",
    "    # def init_hidden(self):\n",
    "    #     return (Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "    #             Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, seq):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            seq.view(len(seq), 1, -1))\n",
    "        outdat = self.hidden2out(lstm_out.view(len(seq), -1))\n",
    "        return outdat\n",
    "\n",
    "\n",
    "def ToVariable(x):\n",
    "    tmp = torch.FloatTensor(x)\n",
    "    return Variable(tmp)\n",
    "\n",
    "\n",
    "def model_training():\n",
    "    print('Start training...\\n')\n",
    "\n",
    "    model = LSTMpred(INPUT_SIZE, HIDDEN_SIZE).cuda()\n",
    "\n",
    "    loss_function = nn.MSELoss()\n",
    "    if OPIMIZER=='Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        for seq, outs in train_y:\n",
    "            seq = ToVariable(seq).cuda()\n",
    "            outs = ToVariable(outs).cuda()\n",
    "            outs=torch.unsqueeze(outs,1)\n",
    "            # outs = torch.from_numpy(np.array([outs]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # model.hidden = model.init_hidden()\n",
    "\n",
    "            modout = model(seq)\n",
    "\n",
    "            loss = loss_function(modout, outs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch:',epoch,'loss',loss.cpu().data.numpy())\n",
    "\n",
    "        torch.save(model,'model_rnn.pkl')\n",
    "\n",
    "def model_test():\n",
    "    model=torch.load('model_rnn.pkl')\n",
    "    predDat = []\n",
    "    for seq, trueVal in dat:\n",
    "        seq = ToVariable(seq)\n",
    "        trueVal = ToVariable(trueVal)\n",
    "        predDat.append(model(seq)[-1].data.numpy()[0])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.title(OPIMIZER)\n",
    "    plt.plot(y)\n",
    "    plt.plot(predDat)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.cuda.set_device(0)\n",
    "    model_training()\n",
    "\n",
    "    model_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
